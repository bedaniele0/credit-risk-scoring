# ============================================================================
# train-model.yml - Automated Model Training & Deployment Pipeline
# ============================================================================
# Pipeline automatizado de reentrenamiento del modelo con:
# - Training programado (schedule)
# - Training on-demand (workflow_dispatch)
# - Validación automática de métricas
# - Registro en MLflow
# - Promoción automática a producción si pasa criterios
# - Notificaciones multi-canal
#
# Autor: Ing. Daniel Varela Perez
# Email: bedaniele0@gmail.com
# Tel: +52 55 4189 3428
# Metodología: DVP-PRO
# ============================================================================

name: Automated Model Training

on:
  # Training programado (primer día del mes a las 2 AM UTC)
  schedule:
    - cron: "0 2 1 * *"  # Monthly retraining

  # Training on-demand
  workflow_dispatch:
    inputs:
      model_type:
        description: "Model type to train"
        required: true
        default: "lightgbm"
        type: choice
        options:
          - lightgbm
          - random_forest
          - logistic_regression
      calibration_method:
        description: "Calibration method"
        required: true
        default: "isotonic"
        type: choice
        options:
          - isotonic
          - sigmoid
          - none
      deploy_if_better:
        description: "Auto-deploy if metrics pass thresholds"
        required: true
        default: true
        type: boolean

  # Training cuando hay cambios en datos
  push:
    paths:
      - "data/raw/**"
      - "src/models/**"
      - "src/features/**"

env:
  PYTHON_VERSION: "3.10"
  MIN_AUC_ROC: 0.75
  MIN_KS_STATISTIC: 0.30
  MIN_RECALL: 0.70
  MAX_BRIER_SCORE: 0.20
  MIN_EXPECTED_SAVINGS: 1000000  # MXN

jobs:
  # ====================
  # JOB 1: DATA VALIDATION
  # ====================
  validate-data:
    name: Validate Training Data
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          pip install pandas numpy scikit-learn

      - name: Check data availability
        run: |
          python -c "
          import pandas as pd
          import sys

          try:
              df = pd.read_csv('data/raw/UCI_Credit_Card.csv')
              print(f'✓ Data loaded: {len(df)} rows, {len(df.columns)} columns')

              # Validaciones
              assert len(df) >= 10000, 'Insufficient data'
              assert df.isnull().sum().sum() < len(df) * 0.05, 'Too many nulls'

              print('✓ Data validation passed')
          except Exception as e:
              print(f'✗ Data validation failed: {e}')
              sys.exit(1)
          "

      - name: Upload data validation report
        uses: actions/upload-artifact@v3
        with:
          name: data-validation-report
          path: logs/data-validation.log

  # ====================
  # JOB 2: TRAIN MODEL
  # ====================
  train-model:
    name: Train Credit Risk Model
    runs-on: ubuntu-latest
    needs: validate-data

    outputs:
      auc_roc: ${{ steps.extract-metrics.outputs.auc_roc }}
      ks_statistic: ${{ steps.extract-metrics.outputs.ks_statistic }}
      recall: ${{ steps.extract-metrics.outputs.recall }}
      expected_savings: ${{ steps.extract-metrics.outputs.expected_savings }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Cache dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}

      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt
          pip install -e .

      - name: Create directories
        run: |
          mkdir -p models logs data/processed mlruns

      - name: Train model
        run: |
          credit-train \
            --data-path data/raw/UCI_Credit_Card.csv \
            --model-type ${{ github.event.inputs.model_type || 'lightgbm' }} \
            --calibration-method ${{ github.event.inputs.calibration_method || 'isotonic' }} \
            --cost-fp 1000 \
            --cost-fn 10000 \
            --config config/mlflow_config.yaml

      - name: Extract metrics
        id: extract-metrics
        run: |
          python -c "
          import mlflow
          import json

          # Get latest run
          mlflow.set_tracking_uri('file:./mlruns')
          client = mlflow.tracking.MlflowClient()
          experiment = client.get_experiment_by_name('credit-risk-scoring')
          runs = client.search_runs(experiment.experiment_id, order_by=['start_time DESC'], max_results=1)

          if runs:
              run = runs[0]
              metrics = run.data.metrics

              # Export to GitHub outputs
              with open('$GITHUB_OUTPUT', 'a') as f:
                  f.write(f\"auc_roc={metrics.get('test_auc_roc', 0)}\n\")
                  f.write(f\"ks_statistic={metrics.get('test_ks', 0)}\n\")
                  f.write(f\"recall={metrics.get('test_optimal_recall', 0)}\n\")
                  f.write(f\"expected_savings={metrics.get('expected_savings', 0)}\n\")

              print('✓ Metrics extracted successfully')
          "

      - name: Upload model artifact
        uses: actions/upload-artifact@v3
        with:
          name: trained-model
          path: |
            models/final_model.joblib
            mlruns/

      - name: Upload training logs
        uses: actions/upload-artifact@v3
        with:
          name: training-logs
          path: logs/

  # ====================
  # JOB 3: VALIDATE MODEL
  # ====================
  validate-model:
    name: Validate Model Metrics
    runs-on: ubuntu-latest
    needs: train-model

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Validate metrics thresholds
        run: |
          python -c "
          import sys

          auc_roc = float('${{ needs.train-model.outputs.auc_roc }}')
          ks_stat = float('${{ needs.train-model.outputs.ks_statistic }}')
          recall = float('${{ needs.train-model.outputs.recall }}')
          savings = float('${{ needs.train-model.outputs.expected_savings }}')

          min_auc = float('${{ env.MIN_AUC_ROC }}')
          min_ks = float('${{ env.MIN_KS_STATISTIC }}')
          min_recall = float('${{ env.MIN_RECALL }}')
          min_savings = float('${{ env.MIN_EXPECTED_SAVINGS }}')

          print('=' * 80)
          print('MODEL VALIDATION RESULTS')
          print('=' * 80)
          print(f'AUC-ROC:          {auc_roc:.4f} (min: {min_auc:.4f}) {"✓" if auc_roc >= min_auc else "✗"}')
          print(f'KS Statistic:     {ks_stat:.4f} (min: {min_ks:.4f}) {"✓" if ks_stat >= min_ks else "✗"}')
          print(f'Recall:           {recall:.4f} (min: {min_recall:.4f}) {"✓" if recall >= min_recall else "✗"}')
          print(f'Expected Savings: ${savings:,.0f} (min: ${min_savings:,.0f}) {"✓" if savings >= min_savings else "✗"}')
          print('=' * 80)

          # Verificar que pasa todos los criterios
          passed = all([
              auc_roc >= min_auc,
              ks_stat >= min_ks,
              recall >= min_recall,
              savings >= min_savings
          ])

          if passed:
              print('✓ Model passes all validation criteria')
              sys.exit(0)
          else:
              print('✗ Model failed validation criteria')
              sys.exit(1)
          "

  # ====================
  # JOB 4: EVALUATE MODEL
  # ====================
  evaluate-model:
    name: Evaluate Model Performance
    runs-on: ubuntu-latest
    needs: [train-model, validate-model]

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install -e .

      - name: Download model artifact
        uses: actions/download-artifact@v3
        with:
          name: trained-model

      - name: Generate predictions on test set
        run: |
          credit-predict \
            --data-path data/processed/test_data.csv \
            --model-path models/final_model.joblib \
            --output-path data/predictions/predictions_latest.csv

      - name: Evaluate model
        run: |
          credit-evaluate \
            --predictions-path data/predictions/predictions_latest.csv \
            --actuals-path data/processed/test_data.csv \
            --output-dir reports/evaluation

      - name: Upload evaluation report
        uses: actions/upload-artifact@v3
        with:
          name: evaluation-report
          path: reports/evaluation/

  # ====================
  # JOB 5: DEPLOY MODEL
  # ====================
  deploy-model:
    name: Deploy Model to Production
    runs-on: ubuntu-latest
    needs: [train-model, validate-model, evaluate-model]
    if: |
      github.event.inputs.deploy_if_better == 'true' ||
      github.event_name == 'schedule'

    environment:
      name: production-ml
      url: https://credit-risk.yourcompany.com

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download model artifact
        uses: actions/download-artifact@v3
        with:
          name: trained-model

      - name: Deploy to production
        run: |
          echo "Deploying model to production..."
          # Copiar modelo a storage (S3, GCS, Azure Blob)
          # aws s3 cp models/final_model.joblib s3://credit-risk-models/production/

          # Actualizar modelo en API
          # curl -X POST https://credit-risk.yourcompany.com/api/v1/models/update \
          #   -F "model=@models/final_model.joblib"

      - name: Update MLflow Model Registry
        run: |
          python -c "
          import mlflow

          mlflow.set_tracking_uri('${{ secrets.MLFLOW_TRACKING_URI }}')
          client = mlflow.tracking.MlflowClient()

          # Transition to Production
          model_name = 'credit-risk-model'
          latest_version = client.get_latest_versions(model_name, stages=['None'])[0].version

          client.transition_model_version_stage(
              name=model_name,
              version=latest_version,
              stage='Production',
              archive_existing_versions=True
          )

          print(f'✓ Model version {latest_version} promoted to Production')
          "

      - name: Run smoke tests
        run: |
          python -c "
          import requests

          # Test prediction endpoint
          response = requests.post(
              'https://credit-risk.yourcompany.com/api/v1/predict',
              json={'features': {...}}
          )
          assert response.status_code == 200
          print('✓ Smoke tests passed')
          "

  # ====================
  # JOB 6: NOTIFICATIONS
  # ====================
  notify:
    name: Send Notifications
    runs-on: ubuntu-latest
    needs: [train-model, deploy-model]
    if: always()

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          pip install requests pyyaml python-dotenv

      - name: Send success notification
        if: ${{ needs.deploy-model.result == 'success' }}
        run: |
          python -c "
          import requests

          webhook_url = '${{ secrets.SLACK_WEBHOOK_URL }}'

          message = {
              'text': '✅ Model Training & Deployment Successful',
              'attachments': [{
                  'color': 'good',
                  'fields': [
                      {'title': 'AUC-ROC', 'value': '${{ needs.train-model.outputs.auc_roc }}', 'short': True},
                      {'title': 'KS Statistic', 'value': '${{ needs.train-model.outputs.ks_statistic }}', 'short': True},
                      {'title': 'Recall', 'value': '${{ needs.train-model.outputs.recall }}', 'short': True},
                      {'title': 'Expected Savings', 'value': '\$\${{ needs.train-model.outputs.expected_savings }}', 'short': True}
                  ]
              }]
          }

          requests.post(webhook_url, json=message)
          print('✓ Slack notification sent')
          "

      - name: Send failure notification
        if: ${{ needs.deploy-model.result == 'failure' }}
        run: |
          python -c "
          import requests

          webhook_url = '${{ secrets.SLACK_WEBHOOK_URL }}'

          message = {
              'text': '❌ Model Training or Deployment Failed',
              'attachments': [{
                  'color': 'danger',
                  'text': 'Check GitHub Actions logs for details.'
              }]
          }

          requests.post(webhook_url, json=message)
          print('✓ Failure notification sent')
          "

  # ====================
  # JOB 7: MONITORING SETUP
  # ====================
  setup-monitoring:
    name: Setup Monitoring
    runs-on: ubuntu-latest
    needs: deploy-model
    if: success()

    steps:
      - name: Enable drift detection
        run: |
          echo "Enabling drift detection for new model..."
          # Activar monitoreo continuo

      - name: Create Grafana dashboard
        run: |
          echo "Creating Grafana dashboard..."
          # Import dashboard para nuevo modelo

      - name: Schedule drift checks
        run: |
          echo "Scheduling daily drift checks..."
          # Configurar cron job para drift detection
